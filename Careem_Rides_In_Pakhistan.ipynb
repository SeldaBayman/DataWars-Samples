{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48bc1cb",
   "metadata": {},
   "source": [
    "# The Careem Rides Datase/ Data Cleaning Capstone Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eab20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "\n",
    "# to read the dataframe\n",
    "import pandas as pd\n",
    "\n",
    "## Reading the dataset as a dataframe\n",
    "\n",
    "# Reading dataframe\n",
    "df = pd.read_csv('Careem.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "## Discovering the dataset \n",
    "\n",
    "#show the number of cells in the dataframe\n",
    "print(\"dataset size: \", df.size)\n",
    "\n",
    "#show the number of records (rows) in the dataframe\n",
    "print(\"number of trips: \", len(df))\n",
    "\n",
    "#show the number of features (coulmns) in the dataframe\n",
    "print(\"number of features: \", len(df.columns)) \n",
    "\n",
    "df.dtypes\n",
    "\n",
    "## Activities\n",
    "Let's clean the dataset.\n",
    "\n",
    "##### 3. Find out the missing values in each column\n",
    "\n",
    "col_missing_values = df.isnull().sum()\n",
    "col_missing_values\n",
    "\n",
    "##### 4. Drop the columns that have more than 1000 missing values\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop(columns=[\"Reference Code\",\"Rating\",\"Tollgate\",\"Tollgate Details GMT\",\"Amount of Credit Used\",\"Notes\"],axis=1,inplace=True)\n",
    "\n",
    "##### 5. Drop the rows that have a `Service Area` other than `Karachi`\n",
    "\n",
    "df=df[df[\"Service Area\"]== \"Karachi\"]\n",
    "df\n",
    "\n",
    "df = df.drop(df[df['Service Area'] != 'Karachi'].index)\n",
    "\n",
    "\n",
    "##### 6. Fill the missing values of the column `Wait Time Min` with the median of the column\n",
    "\n",
    "df['Wait Time Min'].fillna(df['Wait Time Min'].median(), inplace=True)\n",
    "\n",
    "\n",
    "Wait_Time_Min = df['Wait Time Min'].fillna(mean_Wait_Time_Min)\n",
    "\n",
    "df['Wait Time Min'] = Wait_Time_Min\n",
    "\n",
    "\n",
    "df['Wait Time Min'].fillna(df['Wait Time Min'].median(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7. Fill all missing values in `Credit ID` using backward filling method\n",
    "\n",
    "df['Credit ID'] = df[\"Credit ID\"].bfill()\n",
    "\n",
    "##### 10. Find and drop duplicate rows based on `Booking ID`, `Trip ID`, `Car Model`, `Payment Type`, and `Pickup Location` columns while keeping last row\n",
    "\n",
    "df.drop_duplicates(subset=['Booking ID', 'Trip ID', 'Car Model', 'Pickup Location', 'Payment Type'],\n",
    "                   keep='last', \n",
    "                   inplace = True)\n",
    "\n",
    "# Write your code here\n",
    "credit_card_counts = df['Payment Type'].str.count('Credit Card')\n",
    "credit_card_counts = credit_card_counts.sum()\n",
    "credit_card_counts\n",
    "\n",
    "##### 12. Replace the `Car Type` having `Go Mini` with `GO Mini`\n",
    "\n",
    "df['Car Type'] = df[\"Car Type\"].str.replace(\"Go Mini\",\"GO Mini\")\n",
    "\n",
    "##### 13. Find the trips (rows) whose Column `Car Type` contains the substring `GO` & the locations in column `Pickup Location` contains `University`\n",
    "\n",
    "edu_trips_with_GO = df[(df[\"Car Type\"]str.contains(\"GO\")) & (df[\"Pickup Location\"].str.contains(\"University\"))]\n",
    "\n",
    "edu_trips_with_GO = df[(df['Car Type'].str.contains('GO')) & (df['Pickup Location'].str.contains('University'))]\n",
    "\n",
    "##### 14. How many Values in the Column `Car Type` end with  `+`\n",
    "\n",
    "# Write your code here:\n",
    " df[\"Car Type\"].str.endswith(\"+\").sum()\n",
    "\n",
    "##### 16. Clean the column `Wait Time Min` by selecting outliers and dropping them\n",
    "\n",
    "Wait_Time_plot = df['Wait Time Min'].plot(kind='hist')\n",
    "Wait_Time_plot.set_yscale('log')\n",
    "Wait_Time_plot.set_xlabel('Wait Time Min')\n",
    "Wait_Time_plot.set_ylabel('Frequency')\n",
    "\n",
    "# Write your code here:\n",
    "\n",
    "(40- df[\"Wait Time Min\"].mean()) / (df[\"Wait Time Min\"].std())\n",
    "\n",
    "\n",
    "mask = ((df['Wait Time Min'] - df['Wait Time Min'].mean()) /  df['Wait Time Min'].std()).abs() >= 3.5\n",
    "\n",
    "df = df.drop(df.loc[mask].index)\n",
    "\n",
    "\n",
    "##### 17. Clean the column `Trip Price` by selecting outliers\n",
    "\n",
    "Price_plot = df['Trip Price'].plot(kind='box')\n",
    "Price_plot.set_yscale('log')\n",
    "\n",
    "Q1 = df['Trip Price'].quantile(0.25)\n",
    "Q3 = df['Trip Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ((df['Trip Price'] < Q1 - 1.5 * IQR) | (df['Trip Price'] > Q3 + 1.5 * IQR))\n",
    "\n",
    "df = df.drop(df.loc[mask].index)\n",
    "\n",
    "\n",
    "##### 18. Clean the column `Payment Type` by removing invalid values\n",
    "\n",
    "valid_payment_type = ['Credit Card', 'Cash']\n",
    "\n",
    "df = df.loc[df['Payment Type'].isin(valid_payment_type)]\n",
    "\n",
    "\n",
    "##### 19. Clean the columns `Trip Currency` by removing invalid values\n",
    "\n",
    "valid_currency_type = ['PKR']\n",
    "\n",
    "df = df.loc[df[\"Trip Currency\"].isin(valid_currency_type)]\n",
    "\n",
    "##### 20. Clean the column `Total Distance` by removing invalid values\n",
    "\n",
    "\n",
    "Total_Distance_Cleaned = pd.to_numeric(df[\"Total Distance\"], errors='coerce')\n",
    "\n",
    "\n",
    "### The End!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1974a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
